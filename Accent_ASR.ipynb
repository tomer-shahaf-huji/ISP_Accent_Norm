{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJz6FDU1lRzc",
        "outputId": "8e836edb-9b64-4859-a199-3b7d4470e4b2",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/798.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m788.5/798.6 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.3.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.15.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801360 sha256=17f78b217a17eeaa661306d398553a2bcd35649da9ba7ac7b6b1d9e2c69e2150\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=3f897b9b3a044d016c2bd4e81921712fd8a633c8ca45cd733d109e1dda196ec3\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libsndfile1 is already the newest version (1.0.31-2ubuntu0.1).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base libsox3 libwavpack1\n",
            "Suggested packages:\n",
            "  libsox-fmt-all\n",
            "The following NEW packages will be installed:\n",
            "  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base libsox3 libwavpack1 sox\n",
            "0 upgraded, 7 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 617 kB of archives.\n",
            "After this operation, 1,764 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [240 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [11.2 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [33.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 sox amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [104 kB]\n",
            "Fetched 617 kB in 1s (474 kB/s)\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "(Reading database ... 123595 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../1-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../2-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../3-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libwavpack1:amd64.\n",
            "Preparing to unpack .../4-libwavpack1_5.4.0-1build2_amd64.deb ...\n",
            "Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../5-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../6-sox_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.10/dist-packages (1.3)\n",
            "\u001b[33mDEPRECATION: git+https://github.com/NVIDIA/NeMo.git@main#egg=nemo_toolkit[all] contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nemo_toolkit (from nemo_toolkit[all])\n",
            "  Cloning https://github.com/NVIDIA/NeMo.git (to revision main) to /tmp/pip-install-e8qa8p0z/nemo-toolkit_9f47ccb0f91141febd43064f62105a9a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/NVIDIA/NeMo.git /tmp/pip-install-e8qa8p0z/nemo-toolkit_9f47ccb0f91141febd43064f62105a9a\n",
            "  Resolved https://github.com/NVIDIA/NeMo.git to commit 753c70e5c5cfc6acb7ecfb416374aed59d5d233c\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fiddle (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading fiddle-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting huggingface-hub>=0.24 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (1.26.4)\n",
            "Collecting onnx>=1.7.0 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (2.8.2)\n",
            "Collecting ruamel.yaml (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (1.3.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (71.0.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (2.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (1.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (4.66.5)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (3.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (1.16.0)\n",
            "Collecting black~=24.3 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading black-24.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (8.1.7)\n",
            "Collecting isort<6.0.0,>5.1.0 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading isort-5.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting parameterized (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (7.4.4)\n",
            "Collecting pytest-mock (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pytest_mock-3.14.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting pytest-runner (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pytest_runner-6.0.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (5.0.2)\n",
            "Collecting sphinxcontrib-bibtex (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading sphinxcontrib_bibtex-2.6.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting wandb (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (2.2.1)\n",
            "Collecting hydra-core<=1.3.2,>1.3 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting omegaconf<=2.3 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pytorch-lightning>2.2.1 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchmetrics>=0.11.0 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading torchmetrics-1.4.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (4.42.4)\n",
            "Collecting webdataset>=0.2.86 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading webdataset-0.2.96-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting datasets (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (7.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (2.1.4)\n",
            "Collecting sacremoses>=0.0.43 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: sentencepiece<1.0.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (0.1.99)\n",
            "Collecting braceexpand (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (0.8.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (0.8.0)\n",
            "Collecting g2p-en (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting jiwer (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading jiwer-3.0.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting kaldi-python-io (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading kaldi-python-io-1.2.2.tar.gz (8.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting kaldiio (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading kaldiio-2.18.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting lhotse>=1.26.0 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading lhotse-1.27.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (0.10.2.post1)\n",
            "Collecting marshmallow (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (24.1)\n",
            "Collecting pyannote.core (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pyannote.metrics (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pydub (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pyloudnorm (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting resampy (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (1.13.1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (0.12.1)\n",
            "Collecting sox (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading sox-1.5.0.tar.gz (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting texterrors (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading texterrors-0.5.1.tar.gz (23 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerated-scan (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading accelerated_scan-0.2.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting boto3 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading boto3-1.35.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting faiss-cpu (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting fasttext (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flask-restful (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading Flask_RESTful-0.3.10-py2.py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting ftfy (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading ftfy-6.2.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (5.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (3.11.0)\n",
            "Collecting ijson (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (0.42.1)\n",
            "Collecting markdown2 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading markdown2-2.5.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: matplotlib>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (3.7.1)\n",
            "Requirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (3.8.1)\n",
            "Collecting opencc<1.1.7 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading OpenCC-1.1.6-cp310-cp310-manylinux1_x86_64.whl.metadata (12 kB)\n",
            "Collecting pangu (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pangu-4.0.6.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting rapidfuzz (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting rouge-score (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tensorstore<0.1.46 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading tensorstore-0.1.45-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: tiktoken==0.7.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (0.7.0)\n",
            "Collecting zarr (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading zarr-2.18.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting attrdict (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting janome (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading Janome-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting kornia (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading kornia-0.7.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting pypinyin (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pypinyin-0.52.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pypinyin-dict (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pypinyin_dict-0.8.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting progress>=1.5 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.7 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (0.9.0)\n",
            "Collecting textdistance>=4.1.5 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting addict (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting clip (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading clip-0.2.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting decord (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n",
            "Collecting diffusers>=0.19.3 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading diffusers-0.30.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting einops-exts (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading einops_exts-0.0.4-py3-none-any.whl.metadata (621 bytes)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit->nemo_toolkit[all]) (2.34.2)\n",
            "Collecting nerfacc>=0.5.3 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading nerfacc-0.5.3-py3-none-any.whl.metadata (915 bytes)\n",
            "Collecting open-clip-torch==2.24.0 (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading open_clip_torch-2.24.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting PyMCubes (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading PyMCubes-0.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (868 bytes)\n",
            "Collecting taming-transformers (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading taming_transformers-0.0.1-py3-none-any.whl.metadata (499 bytes)\n",
            "Collecting torchdiffeq (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading torchdiffeq-0.2.4-py3-none-any.whl.metadata (440 bytes)\n",
            "Collecting torchsde (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting trimesh (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading trimesh-4.4.7-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting pesq (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pesq-0.0.4.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pystoi (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting nemo-text-processing (from nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading nemo_text_processing-1.1.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open-clip-torch==2.24.0->nemo_toolkit->nemo_toolkit[all]) (0.18.1+cu121)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open-clip-torch==2.24.0->nemo_toolkit->nemo_toolkit[all]) (2024.5.15)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from open-clip-torch==2.24.0->nemo_toolkit->nemo_toolkit[all]) (3.20.3)\n",
            "Collecting timm (from open-clip-torch==2.24.0->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading timm-1.0.8-py3-none-any.whl.metadata (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.7.0->nemo_toolkit->nemo_toolkit[all]) (2.32.3)\n",
            "Collecting mypy-extensions>=0.4.3 (from black~=24.3->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black~=24.3->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black~=24.3->nemo_toolkit->nemo_toolkit[all]) (4.2.2)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black~=24.3->nemo_toolkit->nemo_toolkit[all]) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black~=24.3->nemo_toolkit->nemo_toolkit[all]) (4.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.19.3->nemo_toolkit->nemo_toolkit[all]) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.19.3->nemo_toolkit->nemo_toolkit[all]) (3.15.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.19.3->nemo_toolkit->nemo_toolkit[all]) (0.4.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.19.3->nemo_toolkit->nemo_toolkit[all]) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->nemo_toolkit->nemo_toolkit[all]) (2024.6.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->nemo_toolkit->nemo_toolkit[all]) (6.0.2)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core<=1.3.2,>1.3->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from lhotse>=1.26.0->nemo_toolkit->nemo_toolkit[all]) (3.0.1)\n",
            "Collecting cytoolz>=0.10.1 (from lhotse>=1.26.0->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading cytoolz-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting intervaltree>=3.1.0 (from lhotse>=1.26.0->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lilcom>=1.1.0 (from lhotse>=1.26.0->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading lilcom-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo_toolkit->nemo_toolkit[all]) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo_toolkit->nemo_toolkit[all]) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo_toolkit->nemo_toolkit[all]) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo_toolkit->nemo_toolkit[all]) (0.4.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo_toolkit->nemo_toolkit[all]) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo_toolkit->nemo_toolkit[all]) (1.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.2->nemo_toolkit->nemo_toolkit[all]) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.2->nemo_toolkit->nemo_toolkit[all]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.2->nemo_toolkit->nemo_toolkit[all]) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.2->nemo_toolkit->nemo_toolkit[all]) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.2->nemo_toolkit->nemo_toolkit[all]) (3.1.2)\n",
            "Requirement already satisfied: rich>=12 in /usr/local/lib/python3.10/dist-packages (from nerfacc>=0.5.3->nemo_toolkit->nemo_toolkit[all]) (13.7.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->nemo_toolkit->nemo_toolkit[all]) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->nemo_toolkit->nemo_toolkit[all]) (1.16.0)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>2.2.1->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading lightning_utilities-0.11.6-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nemo_toolkit->nemo_toolkit[all]) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->nemo_toolkit->nemo_toolkit[all]) (1.17.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit->nemo_toolkit[all]) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit->nemo_toolkit[all]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit->nemo_toolkit[all]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit->nemo_toolkit[all]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit->nemo_toolkit[all]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit->nemo_toolkit[all]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit->nemo_toolkit[all]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit->nemo_toolkit[all]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit->nemo_toolkit[all]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit->nemo_toolkit[all]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit->nemo_toolkit[all]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit->nemo_toolkit[all]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit->nemo_toolkit[all]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit->nemo_toolkit[all]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit->nemo_toolkit[all]) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->nemo_toolkit->nemo_toolkit[all]) (12.6.20)\n",
            "Collecting botocore<1.36.0,>=1.35.4 (from boto3->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading botocore-1.35.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pyarrow>=15.0.0 (from datasets->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->nemo_toolkit->nemo_toolkit[all]) (3.10.5)\n",
            "Collecting pybind11>=2.2 (from fasttext->nemo_toolkit->nemo_toolkit[all])\n",
            "  Using cached pybind11-2.13.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from fiddle->nemo_toolkit->nemo_toolkit[all]) (1.4.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from fiddle->nemo_toolkit->nemo_toolkit[all]) (0.20.3)\n",
            "Collecting libcst (from fiddle->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading libcst-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Collecting aniso8601>=0.82 (from flask-restful->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-restful->nemo_toolkit->nemo_toolkit[all]) (2.2.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from flask-restful->nemo_toolkit->nemo_toolkit[all]) (2024.1)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->nemo_toolkit->nemo_toolkit[all]) (0.2.13)\n",
            "Collecting distance>=0.1.3 (from g2p-en->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools>=8.5.0 in /usr/local/lib/python3.10/dist-packages (from inflect->nemo_toolkit->nemo_toolkit[all]) (10.3.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from inflect->nemo_toolkit->nemo_toolkit[all]) (4.3.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->nemo_toolkit->nemo_toolkit[all]) (4.12.3)\n",
            "Collecting kornia-rs>=0.1.0 (from kornia->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading kornia_rs-0.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting cdifflib (from nemo-text-processing->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading cdifflib-1.2.6.tar.gz (11 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pynini==2.1.6.post1 (from nemo-text-processing->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pynini-2.1.6.post1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nemo_toolkit->nemo_toolkit[all]) (2024.1)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.core->nemo_toolkit->nemo_toolkit[all]) (2.4.0)\n",
            "Collecting pyannote.database>=4.0.1 (from pyannote.metrics->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pyannote.database-5.1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting docopt>=0.6.2 (from pyannote.metrics->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from pyloudnorm->nemo_toolkit->nemo_toolkit[all]) (1.0.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->nemo_toolkit->nemo_toolkit[all]) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->nemo_toolkit->nemo_toolkit[all]) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->nemo_toolkit->nemo_toolkit[all]) (1.2.2)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting portalocker (from sacrebleu->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting colorama (from sacrebleu->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->nemo_toolkit->nemo_toolkit[all]) (4.9.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->nemo_toolkit->nemo_toolkit[all]) (0.19.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx->nemo_toolkit->nemo_toolkit[all]) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx->nemo_toolkit->nemo_toolkit[all]) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx->nemo_toolkit->nemo_toolkit[all]) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx->nemo_toolkit->nemo_toolkit[all]) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx->nemo_toolkit->nemo_toolkit[all]) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx->nemo_toolkit->nemo_toolkit[all]) (2.0.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx->nemo_toolkit->nemo_toolkit[all]) (2.16.1)\n",
            "Requirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from sphinx->nemo_toolkit->nemo_toolkit[all]) (0.18.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx->nemo_toolkit->nemo_toolkit[all]) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx->nemo_toolkit->nemo_toolkit[all]) (2.16.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx->nemo_toolkit->nemo_toolkit[all]) (0.7.16)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx->nemo_toolkit->nemo_toolkit[all]) (1.4.1)\n",
            "Collecting docutils<0.19,>=0.14 (from sphinx->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading docutils-0.17.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pybtex>=0.24 (from sphinxcontrib-bibtex->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pybtex-0.24.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting pybtex-docutils>=1.0.0 (from sphinxcontrib-bibtex->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading pybtex_docutils-1.0.3-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->nemo_toolkit->nemo_toolkit[all]) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->nemo_toolkit->nemo_toolkit[all]) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->nemo_toolkit->nemo_toolkit[all]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->nemo_toolkit->nemo_toolkit[all]) (3.0.3)\n",
            "Collecting plac (from texterrors->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading plac-1.4.3-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting loguru (from texterrors->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from texterrors->nemo_toolkit->nemo_toolkit[all]) (2.4.0)\n",
            "Collecting Levenshtein (from texterrors->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->nemo_toolkit->nemo_toolkit[all]) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Collecting asciitree (from zarr->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numcodecs>=0.10.0 (from zarr->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading numcodecs-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting fasteners (from zarr->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.4->boto3->nemo_toolkit->nemo_toolkit[all]) (2.0.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->nemo_toolkit->nemo_toolkit[all]) (2.22)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz>=0.10.1->lhotse>=1.26.0->nemo_toolkit->nemo_toolkit[all]) (0.12.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-restful->nemo_toolkit->nemo_toolkit[all]) (2.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo_toolkit->nemo_toolkit[all]) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo_toolkit->nemo_toolkit[all]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo_toolkit->nemo_toolkit[all]) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo_toolkit->nemo_toolkit[all]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo_toolkit->nemo_toolkit[all]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo_toolkit->nemo_toolkit[all]) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo_toolkit->nemo_toolkit[all]) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->nemo_toolkit->nemo_toolkit[all]) (2.1.5)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit->nemo_toolkit[all]) (0.12.4)\n",
            "Collecting latexcodec>=1.0.4 (from pybtex>=0.24->sphinxcontrib-bibtex->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading latexcodec-3.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.7.0->nemo_toolkit->nemo_toolkit[all]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.7.0->nemo_toolkit->nemo_toolkit[all]) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.7.0->nemo_toolkit->nemo_toolkit[all]) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12->nerfacc>=0.5.3->nemo_toolkit->nemo_toolkit[all]) (3.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->nemo_toolkit->nemo_toolkit[all]) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->nemo_toolkit->nemo_toolkit[all]) (2.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers>=0.19.3->nemo_toolkit->nemo_toolkit[all]) (3.20.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->nemo_toolkit->nemo_toolkit[all]) (1.7.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit->nemo_toolkit[all])\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12->nerfacc>=0.5.3->nemo_toolkit->nemo_toolkit[all]) (0.1.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit->nemo_toolkit[all]) (1.5.4)\n",
            "Downloading open_clip_torch-2.24.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading black-24.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diffusers-0.30.0-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiwer-3.0.4-py3-none-any.whl (21 kB)\n",
            "Downloading lhotse-1.27.0-py3-none-any.whl (806 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.9/806.9 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nerfacc-0.5.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading OpenCC-1.1.6-cp310-cp310-manylinux1_x86_64.whl (778 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.3/778.3 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorstore-0.1.45-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n",
            "Downloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdataset-0.2.96-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.8/74.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerated_scan-0.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Downloading boto3-1.35.4-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n",
            "Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fiddle-0.3.0-py3-none-any.whl (419 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.8/419.8 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask_RESTful-0.3.10-py2.py3-none-any.whl (26 kB)\n",
            "Downloading ftfy-6.2.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Janome-0.5.0-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kaldiio-2.18.0-py3-none-any.whl (28 kB)\n",
            "Downloading kornia-0.7.3-py2.py3-none-any.whl (833 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m833.3/833.3 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown2-2.5.0-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nemo_text_processing-1.1.0-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynini-2.1.6.post1-cp310-cp310-manylinux_2_28_x86_64.whl (154.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pangu-4.0.6.1-py3-none-any.whl (6.4 kB)\n",
            "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
            "Downloading PyMCubes-0.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.4/318.4 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypinyin-0.52.0-py2.py3-none-any.whl (833 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m833.7/833.7 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypinyin_dict-0.8.0-py2.py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading pytest_mock-3.14.0-py3-none-any.whl (9.9 kB)\n",
            "Using cached pytest_runner-6.0.1-py3-none-any.whl (7.2 kB)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_bibtex-2.6.2-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading taming_transformers-0.0.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdiffeq-0.2.4-py3-none-any.whl (32 kB)\n",
            "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trimesh-4.4.7-py3-none-any.whl (696 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m696.2/696.2 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zarr-2.18.2-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.2/210.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.4-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cytoolz-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading docutils-0.17.1-py2.py3-none-any.whl (575 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.5/575.5 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading kornia_rs-0.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n",
            "Downloading lilcom-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading numcodecs-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pyannote.database-5.1.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pybind11-2.13.5-py3-none-any.whl (240 kB)\n",
            "Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.4/561.4 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybtex_docutils-1.0.3-py3-none-any.whl (6.4 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libcst-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plac-1.4.3-py2.py3-none-any.whl (22 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading timm-1.0.8-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading latexcodec-3.0.0-py3-none-any.whl (18 kB)\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: nemo_toolkit, antlr4-python3-runtime, progress, clip, fasttext, kaldi-python-io, pesq, rouge-score, sox, texterrors, distance, docopt, intervaltree, asciitree, cdifflib\n",
            "  Building wheel for nemo_toolkit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nemo_toolkit: filename=nemo_toolkit-2.0.0rc2-py3-none-any.whl size=4076060 sha256=c89aec2b62d456e8359aa1bbc44303740a032e28c3229d5d582638e0e198754f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-alwu2_b1/wheels/6c/d2/4f/1572b895b6a4dbd9fdf534c882d9bc6e94e700a6db5bb20423\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=e07095a47654bdc44d97f3141a2a3b0a7e405c87297197e97d923ed99ac94a75\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.6-py3-none-any.whl size=9613 sha256=3d85866e7dead664b840ea73b1050db4bd080f3d471e1464fb845d546957413b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/68/5f/c339b20a41659d856c93ccdce6a33095493eb82c3964aac5a1\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-0.2.0-py3-none-any.whl size=6989 sha256=e1ac0f6eecf0a1112c0dc7deb3a6acd565b0d9d658990a802e0df9b7e0449315\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/5c/e6/2c0fdb453a3569188864b17e9676bea8b3b7e160c037117869\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp310-cp310-linux_x86_64.whl size=4246563 sha256=b57f8497c999b511bb6caed0c26c8d597951f434e1c7d97818fe9f3950936ba1\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/a2/00/81db54d3e6a8199b829d58e02cec2ddb20ce3e59fad8d3c92a\n",
            "  Building wheel for kaldi-python-io (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaldi-python-io: filename=kaldi_python_io-1.2.2-py3-none-any.whl size=8952 sha256=a174071689b8b6444eaeadd491a24d4a0d5bf33000fffc9159eeccb5bf108739\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/23/5f/49d3a826be576faf61d84e8028e1914bb36a5586ee2613b087\n",
            "  Building wheel for pesq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pesq: filename=pesq-0.0.4-cp310-cp310-linux_x86_64.whl size=262949 sha256=88992971679ff00909d9daa1c5dac8a88a44af2715d813328f765683edd0020d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/4e/2c/251524370c0fdd659e99639a0fbd0ca5a782c3aafcd456b28d\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=c484c6e002ce05e5d3430356384d3127ace9a3440afa50bdbdf0380fcb6a297d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for sox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sox: filename=sox-1.5.0-py3-none-any.whl size=40036 sha256=e661cfa578926e006e4f64aec19ae2bd2a8a8535733b83e86371add2cedae030\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/e7/7b/8033be3ec5e4994595d01269fc9657c8fd83a0dcbf8536666a\n",
            "  Building wheel for texterrors (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for texterrors: filename=texterrors-0.5.1-cp310-cp310-linux_x86_64.whl size=1067591 sha256=9d36ba00c26c74f2f4547601d8676fbdc909a13902932aafc3f957c5880d049a\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/b3/44/612e60c5d0d1f956213e08ae2c3f73443fde51878c778a9a38\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16257 sha256=71d7ec998f06930d8ee934ebf8f6417d4703034383ba28e7f2a4d6d7325ebecb\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=a682267c43b13a355b41c709f6e4f417519e6b95ef018c39fe26b716a3e7144c\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26096 sha256=a68c5eee2affbd0d8f399cbcb507ffbda56442a6718455dbe57a096f1ef361e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
            "  Building wheel for asciitree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5033 sha256=1a83d4f7a88b5c73e565307f65c109f5f652e39d50bf7175b89d4ac841381161\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/4e/be/1171b40f43b918087657ec57cf3b81fa1a2e027d8755baa184\n",
            "  Building wheel for cdifflib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cdifflib: filename=cdifflib-1.2.6-cp310-cp310-linux_x86_64.whl size=27684 sha256=71b566d6a00b1d5a7e40a255d079802808e4513e112e6faa9d4c0c9099011589\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/a7/fd/8061e24ed08689045cb6d1ca303768dc463b20a5a338174841\n",
            "Successfully built nemo_toolkit antlr4-python3-runtime progress clip fasttext kaldi-python-io pesq rouge-score sox texterrors distance docopt intervaltree asciitree cdifflib\n",
            "Installing collected packages: trampoline, pydub, progress, plac, pesq, pangu, opencc, janome, ijson, docopt, distance, clip, braceexpand, asciitree, antlr4-python3-runtime, aniso8601, addict, xxhash, webdataset, trimesh, textdistance, tensorstore, sox, smmap, setproctitle, sentry-sdk, sacremoses, ruamel.yaml.clib, rapidfuzz, pytest-runner, pypinyin, pynini, pybind11, pyarrow, portalocker, pathspec, parameterized, onnx, omegaconf, numcodecs, mypy-extensions, marshmallow, markdown2, loguru, lilcom, lightning-utilities, libcst, latexcodec, kornia-rs, kaldiio, kaldi-python-io, jmespath, isort, intervaltree, ftfy, fasteners, faiss-cpu, einops-exts, docutils, docker-pycreds, dill, decord, cytoolz, colorama, cdifflib, attrdict, zarr, sacrebleu, ruamel.yaml, rouge-score, resampy, pytest-mock, pystoi, pypinyin-dict, PyMCubes, pyloudnorm, pybtex, pyannote.core, multiprocess, Levenshtein, jiwer, hydra-core, huggingface-hub, gitdb, fiddle, fasttext, botocore, black, texterrors, s3transfer, pybtex-docutils, lhotse, gitpython, g2p-en, flask-restful, diffusers, wandb, torchsde, torchmetrics, torchdiffeq, sphinxcontrib-bibtex, pyannote.database, nerfacc, nemo_toolkit, kornia, datasets, boto3, accelerated-scan, timm, sentence-transformers, pytorch-lightning, pyannote.metrics, nemo-text-processing, taming-transformers, open-clip-torch\n",
            "  Attempting uninstall: tensorstore\n",
            "    Found existing installation: tensorstore 0.1.64\n",
            "    Uninstalling tensorstore-0.1.64:\n",
            "      Successfully uninstalled tensorstore-0.1.64\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.18.1\n",
            "    Uninstalling docutils-0.18.1:\n",
            "      Successfully uninstalled docutils-0.18.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.23.5\n",
            "    Uninstalling huggingface-hub-0.23.5:\n",
            "      Successfully uninstalled huggingface-hub-0.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\n",
            "orbax-checkpoint 0.6.0 requires tensorstore>=0.1.60, but you have tensorstore 0.1.45 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Levenshtein-0.25.1 PyMCubes-0.1.6 accelerated-scan-0.2.0 addict-2.4.0 aniso8601-9.0.1 antlr4-python3-runtime-4.9.3 asciitree-0.3.3 attrdict-2.0.1 black-24.8.0 boto3-1.35.4 botocore-1.35.4 braceexpand-0.1.7 cdifflib-1.2.6 clip-0.2.0 colorama-0.4.6 cytoolz-0.12.3 datasets-2.21.0 decord-0.6.0 diffusers-0.30.0 dill-0.3.8 distance-0.1.3 docker-pycreds-0.4.0 docopt-0.6.2 docutils-0.17.1 einops-exts-0.0.4 faiss-cpu-1.8.0.post1 fasteners-0.19 fasttext-0.9.3 fiddle-0.3.0 flask-restful-0.3.10 ftfy-6.2.3 g2p-en-2.1.0 gitdb-4.0.11 gitpython-3.1.43 huggingface-hub-0.24.6 hydra-core-1.3.2 ijson-3.3.0 intervaltree-3.1.0 isort-5.13.2 janome-0.5.0 jiwer-3.0.4 jmespath-1.0.1 kaldi-python-io-1.2.2 kaldiio-2.18.0 kornia-0.7.3 kornia-rs-0.1.5 latexcodec-3.0.0 lhotse-1.27.0 libcst-1.4.0 lightning-utilities-0.11.6 lilcom-1.8.0 loguru-0.7.2 markdown2-2.5.0 marshmallow-3.22.0 multiprocess-0.70.16 mypy-extensions-1.0.0 nemo-text-processing-1.1.0 nemo_toolkit-2.0.0rc2 nerfacc-0.5.3 numcodecs-0.13.0 omegaconf-2.3.0 onnx-1.16.2 open-clip-torch-2.24.0 opencc-1.1.6 pangu-4.0.6.1 parameterized-0.9.0 pathspec-0.12.1 pesq-0.0.4 plac-1.4.3 portalocker-2.10.1 progress-1.6 pyannote.core-5.0.0 pyannote.database-5.1.0 pyannote.metrics-3.2.1 pyarrow-17.0.0 pybind11-2.13.5 pybtex-0.24.0 pybtex-docutils-1.0.3 pydub-0.25.1 pyloudnorm-0.1.1 pynini-2.1.6.post1 pypinyin-0.52.0 pypinyin-dict-0.8.0 pystoi-0.4.1 pytest-mock-3.14.0 pytest-runner-6.0.1 pytorch-lightning-2.4.0 rapidfuzz-3.9.6 resampy-0.4.3 rouge-score-0.1.2 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 s3transfer-0.10.2 sacrebleu-2.4.3 sacremoses-0.1.1 sentence-transformers-3.0.1 sentry-sdk-2.13.0 setproctitle-1.3.3 smmap-5.0.1 sox-1.5.0 sphinxcontrib-bibtex-2.6.2 taming-transformers-0.0.1 tensorstore-0.1.45 textdistance-4.6.3 texterrors-0.5.1 timm-1.0.8 torchdiffeq-0.2.4 torchmetrics-1.4.1 torchsde-0.2.6 trampoline-0.1.2 trimesh-4.4.7 wandb-0.17.7 webdataset-0.2.96 xxhash-3.5.0 zarr-2.18.2\n"
          ]
        }
      ],
      "source": [
        "## Install dependencies\n",
        "!pip install openai-whisper\n",
        "!pip install wget\n",
        "!apt-get install sox libsndfile1 ffmpeg\n",
        "!pip install text-unidecode\n",
        "!pip install matplotlib>=3.3.2\n",
        "## Install NeMo\n",
        "BRANCH = 'main'\n",
        "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAhsmi6HlRzh",
        "outputId": "24c3a59e-206e-4d45-eb80-58ae6794a68a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import subprocess\n",
        "import editdistance\n",
        "import tarfile\n",
        "import wget\n",
        "import librosa\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import json\n",
        "from google.colab import drive\n",
        "import soundfile as sf\n",
        "import argparse\n",
        "from datasets import load_dataset, Dataset\n",
        "from whisper.normalizers import EnglishTextNormalizer\n",
        "import torch\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import pandas as pd\n",
        "import nemo.collections.asr as nemo_asr\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRFCHmkHOXaC",
        "outputId": "f46f169d-b1b3-445b-daee-70298f62cccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded at: /content/drive/MyDrive/svarah.tar\n"
          ]
        }
      ],
      "source": [
        "# Run this once\n",
        "data_dir = '/content/drive/MyDrive'\n",
        "os.listdir(data_dir)\n",
        "if not os.path.exists(data_dir + '/svarah.tar'):\n",
        "    svarah_url = 'https://indic-asr-public.objectstore.e2enetworks.net/svarah.tar'\n",
        "    svarah_path = wget.download(svarah_url, data_dir)\n",
        "    print(f\"Dataset downloaded at: {svarah_path}\")\n",
        "    tar = tarfile.open(svarah_path)\n",
        "    tar.extractall(path=data_dir)\n",
        "else:\n",
        "  print('data already downloaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YaI1TkMbSH_0"
      },
      "outputs": [],
      "source": [
        "def get_data(split):\n",
        "    js_data = json.loads(split)\n",
        "    aud = {}\n",
        "    aud['path'] = js_data['audio_filepath']\n",
        "    y, sr = sf.read(aud['path'])\n",
        "    aud['array'] = y\n",
        "    aud['sampling_rate'] = sr\n",
        "    return (aud, js_data['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w2s1qsFbVTH3"
      },
      "outputs": [],
      "source": [
        "class eval_dataset(Dataset):\n",
        "\n",
        "  def __init__(self):\n",
        "      self.audios = []\n",
        "      self.sents = []\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.audios)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "      return {\"raw\": self.audios[i]['array'], \"sampling_rate\":self.audios[i]['sampling_rate'],\"audio_path\" :self.audios[i]['path'] , \"reference\":self.sents[i]}\n",
        "\n",
        "  def fill_data(self, aud, sent):\n",
        "      self.audios.append(aud)\n",
        "      self.sents.append(sent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "I_K_D1XdQv7A"
      },
      "outputs": [],
      "source": [
        "manifest_path = '/content/drive/MyDrive/svarah/svarah_manifest.json'\n",
        "train_portion = 0.7\n",
        "with open(manifest_path, 'r') as f:\n",
        "    data = f.read()\n",
        "    splits = data.split('\\n')[:-1]\n",
        "    jsons = [json.loads(split) for split in splits]\n",
        "    for js in jsons:\n",
        "      js['audio_filepath'] = '/content/drive/MyDrive/svarah/'+js['audio_filepath']\n",
        "    splits = [json.dumps(js) for js in jsons]\n",
        "    random.seed(0)\n",
        "    random.shuffle(splits)\n",
        "    train_last_idx = int(len(splits)*train_portion)\n",
        "    train_splits = splits[:train_last_idx]\n",
        "    eval_splits =  splits[train_last_idx:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq9hta_DTpv_",
        "outputId": "3b0688a7-56a4-4160-acf6-2b9f3ecd232b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1997/1997 [00:08<00:00, 226.06it/s]\n"
          ]
        }
      ],
      "source": [
        "da = Parallel(n_jobs=-240)(delayed(get_data)(split) for split in tqdm(eval_splits))\n",
        "eval_set = eval_dataset()\n",
        "for d in da:\n",
        "    eval_set.fill_data(d[0], d[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4_W0lhaQlRzx"
      },
      "outputs": [],
      "source": [
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Yr7gK6Q_MPwt"
      },
      "outputs": [],
      "source": [
        "class AccentASRDecoder(nemo_asr.modules.ConvASRDecoder):\n",
        "  \"\"\"\n",
        "  Alternative ConvASRDecoder including one additional linear layer for learning\n",
        "  the accent transformation matrix. all other layers of the model should be frozen.\n",
        "  \"\"\"\n",
        "  def __init__(self,decoder):\n",
        "    super(AccentASRDecoder, self).__init__(\n",
        "        decoder._feat_in,\n",
        "        decoder._num_classes-1,\n",
        "        vocabulary = decoder.vocabulary\n",
        "        )\n",
        "\n",
        "    self.decoder_layers = decoder.decoder_layers\n",
        "    self.linear = nn.Linear(\n",
        "        in_features=decoder._num_classes,\n",
        "        out_features=decoder._num_classes,\n",
        "        bias=False\n",
        "        )\n",
        "    nn.init.xavier_uniform_(self.linear.weight) # this does not change the logprobs\n",
        "\n",
        "  def forward(self, encoder_output):\n",
        "      # Adapter module forward step\n",
        "      if self.is_adapter_available():\n",
        "          encoder_output = encoder_output.transpose(1, 2)  # [B, T, C]\n",
        "          encoder_output = self.forward_enabled_adapters(encoder_output)\n",
        "          encoder_output = encoder_output.transpose(1, 2)  # [B, C, T]\n",
        "      out = self.decoder_layers(encoder_output)\n",
        "      out = self.linear(out.transpose(1, 2)).transpose(1, 2)\n",
        "\n",
        "      if self.temperature != 1.0:\n",
        "          return torch.nn.functional.log_softmax(\n",
        "              out.transpose(1, 2) / self.temperature, dim=-1\n",
        "          )\n",
        "      return torch.nn.functional.log_softmax(out.transpose(1, 2), dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFZZpYult96G",
        "outputId": "a937884c-c3a1-4c32-f106-5274d42de26b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-23 08:19:53 cloud:68] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemospeechmodels/versions/1.0.0a5/files/QuartzNet15x5Base-En.nemo to /root/.cache/torch/NeMo/NeMo_2.0.0rc2/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo\n",
            "[NeMo I 2024-08-23 08:19:56 common:826] Instantiating model from pre-trained checkpoint\n",
            "[NeMo I 2024-08-23 08:19:57 features:305] PADDING: 16\n",
            "[NeMo I 2024-08-23 08:19:58 save_restore_connector:275] Model EncDecCTCModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc2/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo.\n"
          ]
        }
      ],
      "source": [
        "# load pretrained\n",
        "quartznet = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"QuartzNet15x5Base-En\")\n",
        "\n",
        "# change to our custom decoder\n",
        "quartznet.decoder = AccentASRDecoder(quartznet.decoder)\n",
        "\n",
        "# freeze all layers but the last\n",
        "quartznet.encoder.freeze()\n",
        "for param in quartznet.decoder.decoder_layers.parameters():\n",
        "  param.requires_grad=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHhQNANjdtKb"
      },
      "source": [
        "## Eval on quartznet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M2aLJD1R_L7",
        "outputId": "cea1ee4c-1de9-435a-bb67-efcd57cc6351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Aug 23 08:20:07 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0              26W /  70W |    195MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XWjkJmyeS_7",
        "outputId": "d08f903f-916c-41e1-c4c9-51f688e95fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1997/1997 [02:27<00:00, 13.54it/s]\n"
          ]
        }
      ],
      "source": [
        "hypothesis = []\n",
        "ground_truth = []\n",
        "whisper_norm = EnglishTextNormalizer()\n",
        "model = quartznet.to(\"cuda\").eval()\n",
        "for i in tqdm(range(len(eval_set))):\n",
        "    op = model.transcribe([eval_set[i]['audio_path']], verbose=False)\n",
        "    hypothesis.append(op[0])\n",
        "    ground_truth.append(eval_set[i]['reference'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnpz55pAaT5E",
        "outputId": "ab26fe89-c5d9-4733-fab8-7028061b4fdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER is: 2.780687553566327\n"
          ]
        }
      ],
      "source": [
        "\n",
        "normalized_hypothesis = [whisper_norm(x) if len(whisper_norm(x)) > 0 else 'NA' for x in hypothesis]\n",
        "normalized_reference = [whisper_norm(x) if len(whisper_norm(x)) > 0 else 'NA' for x in ground_truth]\n",
        "\n",
        "ref = ' '.join(normalized_reference).split()\n",
        "pred = ' '.join(normalized_hypothesis).split()\n",
        "print(f'WER is: {editdistance.distance(ref,pred)/len(ref)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUmq3p2Aw_5N"
      },
      "source": [
        "### Training with PyTorch Lightning\n",
        "\n",
        "NeMo models and modules can be used in any PyTorch code where torch.nn.Module is expected.\n",
        "\n",
        "However, NeMo's models are based on [PytorchLightning's](https://github.com/PyTorchLightning/pytorch-lightning) LightningModule and we recommend you use PytorchLightning for training and fine-tuning as it makes using mixed precision and distributed training very easy. So to start, let's create Trainer instance for training on GPU for 50 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "M4apLjSShMog"
      },
      "outputs": [],
      "source": [
        "with open('train_manifest.json','w') as f:\n",
        "  f.write('\\n'.join(train_splits)+'\\n')\n",
        "\n",
        "with open('eval_manifest.json','w') as f:\n",
        "  f.write('\\n'.join(eval_splits)+'\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PXVKBniMlRz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39335d9-f25c-4f0e-a7e1-720b4b64f4dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-23 08:23:49--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/asr/conf/config.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4280 (4.2K) [text/plain]\n",
            "Saving to: ‘configs/config.yaml’\n",
            "\n",
            "\rconfig.yaml           0%[                    ]       0  --.-KB/s               \rconfig.yaml         100%[===================>]   4.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-08-23 08:23:49 (58.5 MB/s) - ‘configs/config.yaml’ saved [4280/4280]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- Config Information ---#\n",
        "try:\n",
        "    from omegaconf import DictConfig\n",
        "    from ruamel.yaml import YAML\n",
        "except ModuleNotFoundError:\n",
        "    from ruamel_yaml import YAML\n",
        "config_path = './configs/config.yaml'\n",
        "\n",
        "if not os.path.exists(config_path):\n",
        "    # Grab the config we'll use in this example\n",
        "    BRANCH = 'main'\n",
        "    !mkdir configs\n",
        "    !wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/examples/asr/conf/config.yaml\n",
        "\n",
        "yaml = YAML(typ='safe')\n",
        "with open(config_path) as f:\n",
        "    params = yaml.load(f)\n",
        "\n",
        "params['model']['train_ds']['manifest_filepath'] = 'train_manifest.json'\n",
        "params['model']['validation_ds']['manifest_filepath'] = 'eval_manifest.json'\n",
        "params['model']['optim']['lr'] = 1e-6\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params['model']"
      ],
      "metadata": {
        "id": "GUMqHhR_xI3G",
        "outputId": "856f6b7a-fe2b-430a-9ae6-4244c2e6f8fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train_ds': {'manifest_filepath': 'train_manifest.json',\n",
              "  'sample_rate': 16000,\n",
              "  'labels': [' ',\n",
              "   'a',\n",
              "   'b',\n",
              "   'c',\n",
              "   'd',\n",
              "   'e',\n",
              "   'f',\n",
              "   'g',\n",
              "   'h',\n",
              "   'i',\n",
              "   'j',\n",
              "   'k',\n",
              "   'l',\n",
              "   'm',\n",
              "   'n',\n",
              "   'o',\n",
              "   'p',\n",
              "   'q',\n",
              "   'r',\n",
              "   's',\n",
              "   't',\n",
              "   'u',\n",
              "   'v',\n",
              "   'w',\n",
              "   'x',\n",
              "   'y',\n",
              "   'z',\n",
              "   \"'\"],\n",
              "  'batch_size': 32,\n",
              "  'trim_silence': True,\n",
              "  'max_duration': 16.7,\n",
              "  'shuffle': True,\n",
              "  'num_workers': 8,\n",
              "  'pin_memory': True,\n",
              "  'is_tarred': False,\n",
              "  'tarred_audio_filepaths': None,\n",
              "  'shuffle_n': 2048,\n",
              "  'bucketing_strategy': 'synced_randomized',\n",
              "  'bucketing_batch_size': None},\n",
              " 'validation_ds': {'manifest_filepath': 'eval_manifest.json',\n",
              "  'sample_rate': 16000,\n",
              "  'labels': [' ',\n",
              "   'a',\n",
              "   'b',\n",
              "   'c',\n",
              "   'd',\n",
              "   'e',\n",
              "   'f',\n",
              "   'g',\n",
              "   'h',\n",
              "   'i',\n",
              "   'j',\n",
              "   'k',\n",
              "   'l',\n",
              "   'm',\n",
              "   'n',\n",
              "   'o',\n",
              "   'p',\n",
              "   'q',\n",
              "   'r',\n",
              "   's',\n",
              "   't',\n",
              "   'u',\n",
              "   'v',\n",
              "   'w',\n",
              "   'x',\n",
              "   'y',\n",
              "   'z',\n",
              "   \"'\"],\n",
              "  'batch_size': 32,\n",
              "  'shuffle': False,\n",
              "  'num_workers': 8,\n",
              "  'pin_memory': True},\n",
              " 'preprocessor': {'_target_': 'nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor',\n",
              "  'normalize': 'per_feature',\n",
              "  'window_size': 0.02,\n",
              "  'sample_rate': 16000,\n",
              "  'window_stride': 0.01,\n",
              "  'window': 'hann',\n",
              "  'features': 64,\n",
              "  'n_fft': 512,\n",
              "  'frame_splicing': 1,\n",
              "  'dither': 1e-05,\n",
              "  'stft_conv': False},\n",
              " 'spec_augment': {'_target_': 'nemo.collections.asr.modules.SpectrogramAugmentation',\n",
              "  'rect_freq': 50,\n",
              "  'rect_masks': 5,\n",
              "  'rect_time': 120},\n",
              " 'encoder': {'_target_': 'nemo.collections.asr.modules.ConvASREncoder',\n",
              "  'feat_in': 64,\n",
              "  'activation': 'relu',\n",
              "  'conv_mask': True,\n",
              "  'jasper': [{'filters': 128,\n",
              "    'repeat': 1,\n",
              "    'kernel': [11],\n",
              "    'stride': [1],\n",
              "    'dilation': [1],\n",
              "    'dropout': 0.0,\n",
              "    'residual': True,\n",
              "    'separable': True,\n",
              "    'se': True,\n",
              "    'se_context_size': -1},\n",
              "   {'filters': 256,\n",
              "    'repeat': 1,\n",
              "    'kernel': [13],\n",
              "    'stride': [1],\n",
              "    'dilation': [1],\n",
              "    'dropout': 0.0,\n",
              "    'residual': True,\n",
              "    'separable': True,\n",
              "    'se': True,\n",
              "    'se_context_size': -1},\n",
              "   {'filters': 256,\n",
              "    'repeat': 1,\n",
              "    'kernel': [15],\n",
              "    'stride': [1],\n",
              "    'dilation': [1],\n",
              "    'dropout': 0.0,\n",
              "    'residual': True,\n",
              "    'separable': True,\n",
              "    'se': True,\n",
              "    'se_context_size': -1},\n",
              "   {'filters': 256,\n",
              "    'repeat': 1,\n",
              "    'kernel': [17],\n",
              "    'stride': [1],\n",
              "    'dilation': [1],\n",
              "    'dropout': 0.0,\n",
              "    'residual': True,\n",
              "    'separable': True,\n",
              "    'se': True,\n",
              "    'se_context_size': -1},\n",
              "   {'filters': 256,\n",
              "    'repeat': 1,\n",
              "    'kernel': [19],\n",
              "    'stride': [1],\n",
              "    'dilation': [1],\n",
              "    'dropout': 0.0,\n",
              "    'residual': True,\n",
              "    'separable': True,\n",
              "    'se': True,\n",
              "    'se_context_size': -1},\n",
              "   {'filters': 256,\n",
              "    'repeat': 1,\n",
              "    'kernel': [21],\n",
              "    'stride': [1],\n",
              "    'dilation': [1],\n",
              "    'dropout': 0.0,\n",
              "    'residual': False,\n",
              "    'separable': True,\n",
              "    'se': True,\n",
              "    'se_context_size': -1},\n",
              "   {'filters': 1024,\n",
              "    'repeat': 1,\n",
              "    'kernel': [1],\n",
              "    'stride': [1],\n",
              "    'dilation': [1],\n",
              "    'dropout': 0.0,\n",
              "    'residual': False,\n",
              "    'separable': True,\n",
              "    'se': True,\n",
              "    'se_context_size': -1}]},\n",
              " 'decoder': {'_target_': 'nemo.collections.asr.modules.ConvASRDecoder',\n",
              "  'feat_in': 1024,\n",
              "  'num_classes': 28,\n",
              "  'vocabulary': [' ',\n",
              "   'a',\n",
              "   'b',\n",
              "   'c',\n",
              "   'd',\n",
              "   'e',\n",
              "   'f',\n",
              "   'g',\n",
              "   'h',\n",
              "   'i',\n",
              "   'j',\n",
              "   'k',\n",
              "   'l',\n",
              "   'm',\n",
              "   'n',\n",
              "   'o',\n",
              "   'p',\n",
              "   'q',\n",
              "   'r',\n",
              "   's',\n",
              "   't',\n",
              "   'u',\n",
              "   'v',\n",
              "   'w',\n",
              "   'x',\n",
              "   'y',\n",
              "   'z',\n",
              "   \"'\"]},\n",
              " 'optim': {'name': 'novograd',\n",
              "  'lr': 1e-06,\n",
              "  'betas': [0.8, 0.5],\n",
              "  'weight_decay': 0.001,\n",
              "  'sched': {'name': 'CosineAnnealing',\n",
              "   'monitor': 'val_loss',\n",
              "   'reduce_on_plateau': False,\n",
              "   'warmup_steps': None,\n",
              "   'warmup_ratio': None,\n",
              "   'min_lr': 0.0,\n",
              "   'last_epoch': -1}}}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params['model']['optim']['lr'] = 0.1"
      ],
      "metadata": {
        "id": "kZSDyX9hp0mH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GUfR6tAK0k2u"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "809e82f9119f465d8606491f7ced2713",
            "b05fcb5baa8245bfaa829300d934af34",
            "8ad3ba19427c4766b151530be3452e19",
            "650cc3cbf3924baaa4c6ffc24bc82d1d",
            "05563979948e494396d57a290feb4cd3",
            "bfb4bf86bb9f401a8ecf400b0d5c04d4",
            "1a843fb3ffb7477dab2ceda254fca469",
            "2d42fe1b993542ce9c9d922ba5a32126",
            "97d85b0ac197412cb66090b4e2031e37",
            "475a878ede994f349a6d7aa85375bbb0",
            "c619a3159f4d4cea86cdd6abebc455cf",
            "e6bc2723047a4e538255862ad7628c5d",
            "dff9a3dae2e24d5f98ab2b31221a352c",
            "7cc7adc3c3c84b29984ffe889d99778e",
            "15674518b0b74c57afbe863d877649b6",
            "b95cbb2ff5fc4ad1968da06115afb197",
            "055fa3395d5b4289b74c52f3d7feadaf",
            "0ca33c8910014020b278e13bbf765e6c",
            "33fb3dad344c4abfb698be10fa491cf7",
            "5093279c4b5f440585be5795c4a8337d",
            "d82efc7437794b54b552693327020c2d",
            "abd9ad87442f463c993b43387af0e666"
          ]
        },
        "id": "kQc4OphEl0R9",
        "outputId": "8a54f9a8-8f3b-438e-e7f4-c68783d42e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-23 08:26:02 modelPT:665] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-23 08:26:02 modelPT:786] Optimizer config = Novograd (\n",
            "    Parameter Group 0\n",
            "        amsgrad: False\n",
            "        betas: [0.8, 0.5]\n",
            "        eps: 1e-08\n",
            "        grad_averaging: False\n",
            "        lr: 0.1\n",
            "        weight_decay: 0.001\n",
            "    )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-23 08:26:02 lr_scheduler:928] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
            "    Scheduler will not be instantiated !\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-23 08:26:02 audio_to_text_dataset:49] Model level config does not contain `sample_rate`, please explicitly provide `sample_rate` to the dataloaders.\n",
            "[NeMo I 2024-08-23 08:26:02 audio_to_text_dataset:49] Model level config does not contain `labels`, please explicitly provide `labels` to the dataloaders.\n",
            "[NeMo I 2024-08-23 08:26:02 collections:196] Dataset loaded with 4517 files totalling 5.89 hours\n",
            "[NeMo I 2024-08-23 08:26:02 collections:197] 142 files were filtered totalling 0.84 hours\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-23 08:26:02 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "      warnings.warn(_create_warning_msg(\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-23 08:26:02 audio_to_text_dataset:49] Model level config does not contain `sample_rate`, please explicitly provide `sample_rate` to the dataloaders.\n",
            "[NeMo I 2024-08-23 08:26:02 audio_to_text_dataset:49] Model level config does not contain `labels`, please explicitly provide `labels` to the dataloaders.\n",
            "[NeMo I 2024-08-23 08:26:02 collections:196] Dataset loaded with 1997 files totalling 2.89 hours\n",
            "[NeMo I 2024-08-23 08:26:02 collections:197] 0 files were filtered totalling 0.00 hours\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-23 08:26:09 modelPT:786] Optimizer config = Novograd (\n",
            "    Parameter Group 0\n",
            "        amsgrad: False\n",
            "        betas: [0.8, 0.5]\n",
            "        eps: 1e-08\n",
            "        grad_averaging: False\n",
            "        lr: 0.1\n",
            "        weight_decay: 0.001\n",
            "    )\n",
            "[NeMo I 2024-08-23 08:26:09 lr_scheduler:948] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x79abd65933a0>\" \n",
            "    will be used during training (effective maximum steps = 142) - \n",
            "    Parameters : \n",
            "    (warmup_steps: null\n",
            "    warmup_ratio: null\n",
            "    min_lr: 0.0\n",
            "    last_epoch: -1\n",
            "    max_steps: 142\n",
            "    )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name              | Type                              | Params | Mode \n",
            "--------------------------------------------------------------------------------\n",
            "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0      | eval \n",
            "1 | encoder           | ConvASREncoder                    | 18.9 M | train\n",
            "2 | decoder           | AccentASRDecoder                  | 30.6 K | train\n",
            "3 | loss              | CTCLoss                           | 0      | eval \n",
            "4 | spec_augmentation | SpectrogramAugmentation           | 0      | eval \n",
            "5 | wer               | WER                               | 0      | eval \n",
            "--------------------------------------------------------------------------------\n",
            "841       Trainable params\n",
            "18.9 M    Non-trainable params\n",
            "18.9 M    Total params\n",
            "75.701    Total estimated model params size (MB)\n",
            "602       Modules in train mode\n",
            "6         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "809e82f9119f465d8606491f7ced2713"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-23 08:26:10 nemo_logging:349] /usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "      self.pid = os.fork()\n",
            "    \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6bc2723047a4e538255862ad7628c5d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Use the smaller learning rate we set before\n",
        "quartznet.setup_optimization(optim_config=DictConfig(params['model']['optim']))\n",
        "\n",
        "# Point to the data we'll use for fine-tuning as the training set\n",
        "quartznet.setup_training_data(train_data_config=params['model']['train_ds'])\n",
        "\n",
        "# Point to the new validation data for fine-tuning\n",
        "quartznet.setup_validation_data(val_data_config=params['model']['validation_ds'])\n",
        "\n",
        "# And now we can create a PyTorch Lightning trainer and call `fit` again.\n",
        "trainer = pl.Trainer(devices=1, max_epochs=1)\n",
        "trainer.fit(quartznet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsm4nD_G3TKv"
      },
      "source": [
        "## Eval on ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhLH3YLp687h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IiuFVnM24av",
        "outputId": "f8179bcd-a5c8-46bc-d99f-ddb2dfc7dd22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-21 21:01:29 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_2.0.0rc2/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo.\n",
            "[NeMo I 2024-08-21 21:01:29 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_2.0.0rc2/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo\n",
            "[NeMo I 2024-08-21 21:01:29 common:826] Instantiating model from pre-trained checkpoint\n",
            "[NeMo I 2024-08-21 21:01:31 features:305] PADDING: 16\n",
            "[NeMo I 2024-08-21 21:01:34 save_restore_connector:275] Model EncDecCTCModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc2/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo.\n"
          ]
        }
      ],
      "source": [
        "# load model\n",
        "model = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"QuartzNet15x5Base-En\")\n",
        "\n",
        "# change decoder\n",
        "model.decoder = AccentASRDecoder(quartznet.decoder).to('cuda')\n",
        "\n",
        "# load weights\n",
        "model_ckpt='/content/lightning_logs/version_1/checkpoints/epoch=0-step=142.ckpt'\n",
        "model.load_state_dict(torch.load(model_ckpt)['state_dict'], strict=True)\n",
        "model = model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB0-rNa733q8",
        "outputId": "47ca765a-f9aa-4c67-ff66-156e9df4dacc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1997/1997 [02:21<00:00, 14.16it/s]\n"
          ]
        }
      ],
      "source": [
        "hypothesis = []\n",
        "ground_truth = []\n",
        "whisper_norm = EnglishTextNormalizer()\n",
        "model = quartznet.to(\"cuda\").eval()\n",
        "for i in tqdm(range(len(eval_set))):\n",
        "    op = model.transcribe([eval_set[i]['audio_path']],verbose=False)\n",
        "    hypothesis.append(op[0])\n",
        "    ground_truth.append(eval_set[i]['reference'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoQAEL574baM",
        "outputId": "1fc59d85-e9c8-4b7d-f189-436400081148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER is: 0.6914579563851062\n"
          ]
        }
      ],
      "source": [
        "normalized_hypothesis = [whisper_norm(x) if len(whisper_norm(x)) > 0 else 'NA' for x in hypothesis]\n",
        "normalized_reference = [whisper_norm(x) if len(whisper_norm(x)) > 0 else 'NA' for x in ground_truth]\n",
        "\n",
        "ref = ' '.join(normalized_reference).split()\n",
        "pred = ' '.join(normalized_hypothesis).split()\n",
        "print(f'WER is: {editdistance.distance(ref,pred)/len(ref)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWtzwL5qXTYq"
      },
      "source": [
        "With that, we can start training with just one line!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpYXX-GslR0E"
      },
      "source": [
        "There we go! We've put together a full training pipeline for the model and trained it for 50 epochs.\n",
        "\n",
        "If you'd like to save this model checkpoint for loading later (e.g. for fine-tuning, or for continuing training), you can simply call `first_asr_model.save_to(<checkpoint_path>)`. Then, to restore your weights, you can rebuild the model using the config (let's say you call it `first_asr_model_continued` this time) and call `first_asr_model_continued.restore_from(<checkpoint_path>)`.\n",
        "\n",
        "### After Training: Monitoring Progress and Changing Hyperparameters\n",
        "We can  now start Tensorboard to see how training went. Recall that WER stands for Word Error Rate and so the lower it is, the better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_0y3stSXDX_"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  from google import colab\n",
        "  COLAB_ENV = True\n",
        "except (ImportError, ModuleNotFoundError):\n",
        "  COLAB_ENV = False\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "if COLAB_ENV:\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir lightning_logs/\n",
        "else:\n",
        "  print(\"To use tensorboard, please use this notebook in a Google Colab environment.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0h-BME7U8yb"
      },
      "source": [
        "We could improve this model by playing with hyperparameters. We can look at the current hyperparameters with the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kdQbpohXnEd"
      },
      "outputs": [],
      "source": [
        "print(params['model']['optim'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGZzRCvIW8kE"
      },
      "source": [
        "Let's say we wanted to change the learning rate. To do so, we can create a `new_opt` dict and set our desired learning rate, then call `<model>.setup_optimization()` with the new optimization parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbigFKUtYgvn"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "new_opt = copy.deepcopy(params['model']['optim'])\n",
        "new_opt['lr'] = 0.001\n",
        "first_asr_model.setup_optimization(optim_config=DictConfig(new_opt))\n",
        "# And then you can invoke trainer.fit(first_asr_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5Kwg8Cz-aaO"
      },
      "source": [
        "## Inference\n",
        "\n",
        "Let's have a quick look at how one could run inference with NeMo's ASR model.\n",
        "\n",
        "First, ``EncDecCTCModel`` and its subclasses contain a handy ``transcribe`` method which can be used to simply obtain audio files' transcriptions. It also has batch_size argument to improve performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FT0klSV268p"
      },
      "outputs": [],
      "source": [
        "audio = [os.path.join(data_dir, 'an4/wav/an4_clstk/mgah/cen2-mgah-b.wav'),\n",
        "                     os.path.join(data_dir, 'an4/wav/an4_clstk/fmjd/cen7-fmjd-b.wav'),\n",
        "                     os.path.join(data_dir, 'an4/wav/an4_clstk/fmjd/cen8-fmjd-b.wav'),\n",
        "                     os.path.join(data_dir, 'an4/wav/an4_clstk/fkai/cen8-fkai-b.wav')]\n",
        "print(first_asr_model.transcribe(audio=audio,\n",
        "                                 batch_size=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FiCfLX0D7py"
      },
      "source": [
        "Below is an example of a simple inference loop in pure PyTorch. It also shows how one can compute Word Error Rate (WER) metric between predictions and references."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mP4r1Gx_Ilt"
      },
      "outputs": [],
      "source": [
        "# Bigger batch-size = bigger throughput\n",
        "params['model']['validation_ds']['batch_size'] = 16\n",
        "\n",
        "# Setup the test data loader and make sure the model is on GPU\n",
        "first_asr_model.setup_test_data(test_data_config=params['model']['validation_ds'])\n",
        "first_asr_model.cuda()\n",
        "first_asr_model.eval()\n",
        "\n",
        "# We will be computing Word Error Rate (WER) metric between our hypothesis and predictions.\n",
        "# WER is computed as numerator/denominator.\n",
        "# We'll gather all the test batches' numerators and denominators.\n",
        "wer_nums = []\n",
        "wer_denoms = []\n",
        "\n",
        "# Loop over all test batches.\n",
        "# Iterating over the model's `test_dataloader` will give us:\n",
        "# (audio_signal, audio_signal_length, transcript_tokens, transcript_length)\n",
        "# See the AudioToCharDataset for more details.\n",
        "for test_batch in first_asr_model.test_dataloader():\n",
        "        test_batch = [x.cuda() for x in test_batch]\n",
        "        targets = test_batch[2]\n",
        "        targets_lengths = test_batch[3]\n",
        "        log_probs, encoded_len, greedy_predictions = first_asr_model(\n",
        "            input_signal=test_batch[0], input_signal_length=test_batch[1]\n",
        "        )\n",
        "        # Notice the model has a helper object to compute WER\n",
        "        first_asr_model.wer.update(predictions=greedy_predictions, predictions_lengths=None, targets=targets, targets_lengths=targets_lengths)\n",
        "        _, wer_num, wer_denom = first_asr_model.wer.compute()\n",
        "        first_asr_model.wer.reset()\n",
        "        wer_nums.append(wer_num.detach().cpu().numpy())\n",
        "        wer_denoms.append(wer_denom.detach().cpu().numpy())\n",
        "\n",
        "        # Release tensors from GPU memory\n",
        "        del test_batch, log_probs, targets, targets_lengths, encoded_len, greedy_predictions\n",
        "\n",
        "# We need to sum all numerators and denominators first. Then divide.\n",
        "print(f\"WER = {sum(wer_nums)/sum(wer_denoms)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kM9kBNOCptf"
      },
      "source": [
        "This WER is not particularly impressive and could be significantly improved. You could train longer (try 100 epochs) to get a better number. Check out the next section on how to improve it further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBcJtg5ulR0H"
      },
      "source": [
        "## Model Improvements\n",
        "\n",
        "You already have all you need to create your own ASR model in NeMo, but there are a few more tricks that you can employ if you so desire. In this section, we'll briefly cover a few possibilities for improving an ASR model.\n",
        "\n",
        "### Data Augmentation\n",
        "\n",
        "There exist several ASR data augmentation methods that can increase the size of our training set.\n",
        "\n",
        "For example, we can perform augmentation on the spectrograms by zeroing out specific frequency segments (\"frequency masking\") or time segments (\"time masking\") as described by [SpecAugment](https://arxiv.org/abs/1904.08779), or zero out rectangles on the spectrogram as in [Cutout](https://arxiv.org/pdf/1708.04552.pdf). In NeMo, we can do all three of these by simply adding in a `SpectrogramAugmentation` neural module. (As of now, it does not perform the time warping from the SpecAugment paper.)\n",
        "\n",
        "Our toy model does not do spectrogram augmentation. But the real one we got from cloud does:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9glGogaPlR0H"
      },
      "outputs": [],
      "source": [
        "print(quartznet._cfg['spec_augment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdwdcA_a640R"
      },
      "source": [
        "If you want to enable SpecAugment in your model, make sure your .yaml config file contains 'model/spec_augment' section which looks like the one above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f142kIQc1Z2"
      },
      "source": [
        "### Transfer learning\n",
        "\n",
        "Transfer learning is an important machine learning technique that uses a model’s knowledge of one task to make it perform better on another. Fine-tuning is one of the techniques to perform transfer learning. It is an essential part of the recipe for many state-of-the-art results where a base model is first pretrained on a task with abundant training data and then fine-tuned on different tasks of interest where the training data is less abundant or even scarce.\n",
        "\n",
        "In ASR you might want to do fine-tuning in multiple scenarios, for example, when you want to improve your model's performance on a particular domain (medical, financial, etc.) or on accented speech. You can even transfer learn from one language to another! Check out [this paper](https://arxiv.org/abs/2005.04290) for examples.\n",
        "\n",
        "Transfer learning with NeMo is simple. Let's demonstrate how the model we got from the cloud could be fine-tuned on AN4 data. (NOTE: this is a toy example). And, while we are at it, we will change model's vocabulary, just to demonstrate how it's done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl320dsydWX0"
      },
      "outputs": [],
      "source": [
        "# Check what kind of vocabulary/alphabet the model has right now\n",
        "print(quartznet.decoder.vocabulary)\n",
        "\n",
        "# Let's add \"!\" symbol there. Note that you can (and should!) change the vocabulary\n",
        "# entirely when fine-tuning using a different language.\n",
        "quartznet.change_vocabulary(\n",
        "    new_vocabulary=[\n",
        "        ' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n',\n",
        "        'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", \"!\"\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7lvmiMSd3Aw"
      },
      "source": [
        "After this, our decoder has completely changed, but our encoder (which is where most of the weights are) remained intact. Let's fine tune-this model for 2 epochs on AN4 dataset. We will also use the smaller learning rate from ``new_opt` (see the \"After Training\" section)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PZJIso-eDl-"
      },
      "outputs": [],
      "source": [
        "# Use the smaller learning rate we set before\n",
        "quartznet.setup_optimization(optim_config=DictConfig(new_opt))\n",
        "\n",
        "# Point to the data we'll use for fine-tuning as the training set\n",
        "quartznet.setup_training_data(train_data_config=params['model']['train_ds'])\n",
        "\n",
        "# Point to the new validation data for fine-tuning\n",
        "quartznet.setup_validation_data(val_data_config=params['model']['validation_ds'])\n",
        "\n",
        "# And now we can create a PyTorch Lightning trainer and call `fit` again.\n",
        "trainer = pl.Trainer(devices=1, accelerator='gpu', max_epochs=2)\n",
        "trainer.fit(quartznet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VURa1NavlR0U"
      },
      "source": [
        "### Fast Training\n",
        "\n",
        "Last but not least, we could simply speed up training our model! If you have the resources, you can speed up training by splitting the workload across multiple GPUs. Otherwise (or in addition), there's always mixed precision training, which allows you to increase your batch size.\n",
        "\n",
        "You can use [PyTorch Lightning's Trainer object](https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html?highlight=Trainer) to handle mixed-precision and distributed training for you. Below are some examples of flags you would pass to the `Trainer` to use these features:\n",
        "\n",
        "```python\n",
        "# Mixed precision:\n",
        "trainer = pl.Trainer(amp_level='O1', precision=16)\n",
        "\n",
        "# Trainer with a distributed backend:\n",
        "trainer = pl.Trainer(devices=2, num_nodes=2, accelerator='gpu', strategy='ddp')\n",
        "\n",
        "# Of course, you can combine these flags as well.\n",
        "```\n",
        "\n",
        "Finally, have a look at [example scripts in NeMo repository](https://github.com/NVIDIA/NeMo/blob/stable/examples/asr/asr_ctc/speech_to_text_ctc.py) which can handle mixed precision and distributed training using command-line arguments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1ym8QT3jQnj"
      },
      "source": [
        "### Deployment\n",
        "\n",
        "Note: It is recommended to run the deployment code from the NVIDIA PyTorch container.\n",
        "\n",
        "Let's get back to our pre-trained model and see how easy it can be exported to an ONNX file\n",
        "in order to run it in an inference engine like TensorRT or ONNXRuntime.\n",
        "\n",
        "If you are running in an environment outside of the NVIDIA PyTorch container (like Google Colab for example) then you will have to build the onnxruntime and onnxruntime-gpu. The cell below gives an example of how to build those runtimes but the example may have to be adapted depending on your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4WRcmakjQnj"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade onnxruntime # for gpu, use onnxruntime-gpu\n",
        "#!mkdir -p ort\n",
        "#%cd ort\n",
        "#!git clean -xfd\n",
        "#!git clone --depth 1 --branch v1.8.0 https://github.com/microsoft/onnxruntime.git .\n",
        "#!./build.sh --skip_tests --config Release --build_shared_lib --parallel --use_cuda --cuda_home /usr/local/cuda --cudnn_home /usr/lib/#x86_64-linux-gnu --build_wheel\n",
        "#!pip uninstall -y onnxruntime\n",
        "#!pip uninstall -y onnxruntime-gpu\n",
        "#!pip install  --upgrade --force-reinstall ./build/Linux/Release/dist/onnxruntime*.whl\n",
        "#%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9yO1BEbjQnm"
      },
      "source": [
        "Then run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZnyWxPyjQnm"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import tempfile\n",
        "import onnxruntime\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import nemo.collections.asr as nemo_asr\n",
        "from nemo.collections.asr.data.audio_to_text import AudioToCharDataset\n",
        "from nemo.collections.asr.metrics.wer import WER\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "def setup_transcribe_dataloader(cfg, vocabulary):\n",
        "    config = {\n",
        "        'manifest_filepath': os.path.join(cfg['temp_dir'], 'manifest.json'),\n",
        "        'sample_rate': 16000,\n",
        "        'labels': vocabulary,\n",
        "        'batch_size': min(cfg['batch_size'], len(cfg['audio'])),\n",
        "        'trim_silence': True,\n",
        "        'shuffle': False,\n",
        "    }\n",
        "    dataset = AudioToCharDataset(\n",
        "        manifest_filepath=config['manifest_filepath'],\n",
        "        labels=config['labels'],\n",
        "        sample_rate=config['sample_rate'],\n",
        "        int_values=config.get('int_values', False),\n",
        "        augmentor=None,\n",
        "        max_duration=config.get('max_duration', None),\n",
        "        min_duration=config.get('min_duration', None),\n",
        "        max_utts=config.get('max_utts', 0),\n",
        "        blank_index=config.get('blank_index', -1),\n",
        "        unk_index=config.get('unk_index', -1),\n",
        "        normalize=config.get('normalize_transcripts', False),\n",
        "        trim=config.get('trim_silence', True),\n",
        "        parser=config.get('parser', 'en'),\n",
        "    )\n",
        "    return torch.utils.data.DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=config['batch_size'],\n",
        "        collate_fn=dataset.collate_fn,\n",
        "        drop_last=config.get('drop_last', False),\n",
        "        shuffle=False,\n",
        "        num_workers=config.get('num_workers', 0),\n",
        "        pin_memory=config.get('pin_memory', False),\n",
        "    )\n",
        "\n",
        "quartznet = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"QuartzNet15x5Base-En\")\n",
        "\n",
        "quartznet.export('qn.onnx')\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession('qn.onnx', providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "\n",
        "with tempfile.TemporaryDirectory() as tmpdir:\n",
        "    with open(os.path.join(tmpdir, 'manifest.json'), 'w') as fp:\n",
        "        for audio_file in files:\n",
        "            entry = {'audio_filepath': audio_file, 'duration': 100000, 'text': 'nothing'}\n",
        "            fp.write(json.dumps(entry) + '\\n')\n",
        "\n",
        "    config = {'audio': files, 'batch_size': 4, 'temp_dir': tmpdir}\n",
        "    temporary_datalayer = setup_transcribe_dataloader(config, quartznet.decoder.vocabulary)\n",
        "    for test_batch in temporary_datalayer:\n",
        "        processed_signal, processed_signal_len = quartznet.preprocessor(\n",
        "            input_signal=test_batch[0].to(quartznet.device), length=test_batch[1].to(quartznet.device)\n",
        "        )\n",
        "        ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(processed_signal),}\n",
        "        ologits = ort_session.run(None, ort_inputs)\n",
        "        alogits = np.asarray(ologits)\n",
        "        logits = torch.from_numpy(alogits[0])\n",
        "        greedy_predictions = logits.argmax(dim=-1, keepdim=False)\n",
        "        wer = WER(decoding=quartznet.decoding, use_cer=False)\n",
        "        hypotheses, _ = wer.decoding.ctc_decoder_predictions_tensor(greedy_predictions)\n",
        "        print(hypotheses)\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wteGqroafWg1"
      },
      "source": [
        "## Under the Hood\n",
        "\n",
        "NeMo is open-source and we do all our model development in the open, so you can inspect our code if you wish.\n",
        "\n",
        "In particular, ``nemo_asr.model.EncDecCTCModel`` is an encoder-decoder model which is constructed using several ``Neural Modules`` taken from ``nemo_asr.modules.`` Here is what its forward pass looks like:\n",
        "```python\n",
        "def forward(self, input_signal, input_signal_length):\n",
        "    processed_signal, processed_signal_len = self.preprocessor(\n",
        "        input_signal=input_signal, length=input_signal_length,\n",
        "    )\n",
        "    # Spec augment is not applied during evaluation/testing\n",
        "    if self.spec_augmentation is not None and self.training:\n",
        "        processed_signal = self.spec_augmentation(input_spec=processed_signal)\n",
        "    encoded, encoded_len = self.encoder(audio_signal=processed_signal, length=processed_signal_len)\n",
        "    log_probs = self.decoder(encoder_output=encoded)\n",
        "    greedy_predictions = log_probs.argmax(dim=-1, keepdim=False)\n",
        "    return log_probs, encoded_len, greedy_predictions\n",
        "```\n",
        "Here:\n",
        "\n",
        "* ``self.preprocessor`` is an instance of ``nemo_asr.modules.AudioToMelSpectrogramPreprocessor``, which is a neural module that takes audio signal and converts it into a Mel-Spectrogram\n",
        "* ``self.spec_augmentation`` - is a neural module of type ```nemo_asr.modules.SpectrogramAugmentation``, which implements data augmentation.\n",
        "* ``self.encoder`` - is a convolutional Jasper/QuartzNet-like encoder of type ``nemo_asr.modules.ConvASREncoder``\n",
        "* ``self.decoder`` - is a ``nemo_asr.modules.ConvASRDecoder`` which simply projects into the target alphabet (vocabulary).\n",
        "\n",
        "Also, ``EncDecCTCModel`` uses the audio dataset class ``nemo_asr.data.AudioToCharDataset`` and CTC loss implemented in ``nemo_asr.losses.CTCLoss``.\n",
        "\n",
        "You can use these and other neural modules (or create new ones yourself!) to construct new ASR models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smzlvbhelR0U"
      },
      "source": [
        "# Further Reading/Watching:\n",
        "\n",
        "That's all for now! If you'd like to learn more about the topics covered in this tutorial, here are some resources that may interest you:\n",
        "- [Stanford Lecture on ASR](https://www.youtube.com/watch?v=3MjIkWxXigM)\n",
        "- [\"An Intuitive Explanation of Connectionist Temporal Classification\"](https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c)\n",
        "- [Explanation of CTC with Prefix Beam Search](https://medium.com/corti-ai/ctc-networks-and-language-models-prefix-beam-search-explained-c11d1ee23306)\n",
        "- [Listen Attend and Spell Paper (seq2seq ASR model)](https://arxiv.org/abs/1508.01211)\n",
        "- [Explanation of the mel spectrogram in more depth](https://towardsdatascience.com/getting-to-know-the-mel-spectrogram-31bca3e2d9d0)\n",
        "- [Jasper Paper](https://arxiv.org/abs/1904.03288)\n",
        "- [QuartzNet paper](https://arxiv.org/abs/1910.10261)\n",
        "- [SpecAugment Paper](https://arxiv.org/abs/1904.08779)\n",
        "- [Explanation and visualization of SpecAugment](https://towardsdatascience.com/state-of-the-art-audio-data-augmentation-with-google-brains-specaugment-and-pytorch-d3d1a3ce291e)\n",
        "- [Cutout Paper](https://arxiv.org/pdf/1708.04552.pdf)\n",
        "- [Transfer Learning Blogpost](https://developer.nvidia.com/blog/jump-start-training-for-speech-recognition-models-with-nemo/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3ERGX86lR0V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "809e82f9119f465d8606491f7ced2713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b05fcb5baa8245bfaa829300d934af34",
              "IPY_MODEL_8ad3ba19427c4766b151530be3452e19",
              "IPY_MODEL_650cc3cbf3924baaa4c6ffc24bc82d1d"
            ],
            "layout": "IPY_MODEL_05563979948e494396d57a290feb4cd3"
          }
        },
        "b05fcb5baa8245bfaa829300d934af34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfb4bf86bb9f401a8ecf400b0d5c04d4",
            "placeholder": "​",
            "style": "IPY_MODEL_1a843fb3ffb7477dab2ceda254fca469",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "8ad3ba19427c4766b151530be3452e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d42fe1b993542ce9c9d922ba5a32126",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97d85b0ac197412cb66090b4e2031e37",
            "value": 2
          }
        },
        "650cc3cbf3924baaa4c6ffc24bc82d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_475a878ede994f349a6d7aa85375bbb0",
            "placeholder": "​",
            "style": "IPY_MODEL_c619a3159f4d4cea86cdd6abebc455cf",
            "value": " 2/2 [00:03&lt;00:00,  0.54it/s]"
          }
        },
        "05563979948e494396d57a290feb4cd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "bfb4bf86bb9f401a8ecf400b0d5c04d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a843fb3ffb7477dab2ceda254fca469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d42fe1b993542ce9c9d922ba5a32126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97d85b0ac197412cb66090b4e2031e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "475a878ede994f349a6d7aa85375bbb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c619a3159f4d4cea86cdd6abebc455cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6bc2723047a4e538255862ad7628c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dff9a3dae2e24d5f98ab2b31221a352c",
              "IPY_MODEL_7cc7adc3c3c84b29984ffe889d99778e",
              "IPY_MODEL_15674518b0b74c57afbe863d877649b6"
            ],
            "layout": "IPY_MODEL_b95cbb2ff5fc4ad1968da06115afb197"
          }
        },
        "dff9a3dae2e24d5f98ab2b31221a352c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_055fa3395d5b4289b74c52f3d7feadaf",
            "placeholder": "​",
            "style": "IPY_MODEL_0ca33c8910014020b278e13bbf765e6c",
            "value": "Epoch 0:  56%"
          }
        },
        "7cc7adc3c3c84b29984ffe889d99778e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33fb3dad344c4abfb698be10fa491cf7",
            "max": 142,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5093279c4b5f440585be5795c4a8337d",
            "value": 80
          }
        },
        "15674518b0b74c57afbe863d877649b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d82efc7437794b54b552693327020c2d",
            "placeholder": "​",
            "style": "IPY_MODEL_abd9ad87442f463c993b43387af0e666",
            "value": " 80/142 [03:46&lt;02:55,  0.35it/s, v_num=0]"
          }
        },
        "b95cbb2ff5fc4ad1968da06115afb197": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "055fa3395d5b4289b74c52f3d7feadaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ca33c8910014020b278e13bbf765e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33fb3dad344c4abfb698be10fa491cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5093279c4b5f440585be5795c4a8337d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d82efc7437794b54b552693327020c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abd9ad87442f463c993b43387af0e666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}